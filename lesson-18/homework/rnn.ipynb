{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TizH0jkOwL5P"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!wget https://raw.githubusercontent.com/karpathy/makemore/refs/heads/master/names.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MtqbI0FLwP48",
    "outputId": "deb49bb4-f625-4864-af3f-403e9f5188a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WfcFJwdfwSC2"
   },
   "outputs": [],
   "source": [
    "names = open('names.txt').read().splitlines()\n",
    "\n",
    "# tokenizer\n",
    "vocab = sorted(set(''.join(names) + '.'))\n",
    "vocab_size = len(vocab)\n",
    "stoi = {v:k for k, v in enumerate(vocab)}\n",
    "itos = {v:k for k, v in stoi.items()}\n",
    "\n",
    "def decode(seq: list[int]) -> str:\n",
    "    return ''.join([itos[i] for i in seq])\n",
    "\n",
    "def encode(name: str) -> list[int]:\n",
    "    return [stoi[s] for s in name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aTkM7VETwUja"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for name in names:\n",
    "    name = '.' + name + '.'\n",
    "    name = encode(name)\n",
    "    X.append(name[:-1])\n",
    "    Y.append(name[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hH5h6KY_9L5O",
    "outputId": "07b2f70d-1575-45dd-802b-00d81c1e6706"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 5, 13, 13, 1],\n",
       " [0, 15, 12, 9, 22, 9, 1],\n",
       " [0, 1, 22, 1],\n",
       " [0, 9, 19, 1, 2, 5, 12, 12, 1],\n",
       " [0, 19, 15, 16, 8, 9, 1]]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_cNsxd819TDY",
    "outputId": "068d2fc7-a065-44fc-dd6d-616ecc2be566"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 13, 13, 1, 0],\n",
       " [15, 12, 9, 22, 9, 1, 0],\n",
       " [1, 22, 1, 0],\n",
       " [9, 19, 1, 2, 5, 12, 12, 1, 0],\n",
       " [19, 15, 16, 8, 9, 1, 0]]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2RIWCPlCDtgD",
    "outputId": "458601b1-2b11-4bf6-f633-69ca49ed2e52"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 5, 13, 13]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = [0, 5, 13, 13, 1]\n",
    "t = 4\n",
    "x[:t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bGWlVdiR_Hf3"
   },
   "outputs": [],
   "source": [
    "n_embd = 4\n",
    "\n",
    "# Model init\n",
    "E = torch.randn(vocab_size, n_embd)\n",
    "W1 = torch.randn(n_embd, 10)\n",
    "b1 = torch.randn(10)\n",
    "W2 = torch.randn(10, 20)\n",
    "b2 = torch.randn(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AH_Gh1fB_Hdp"
   },
   "outputs": [],
   "source": [
    "# Model forward\n",
    "x = [0, 5, 13, 13, 1]\n",
    "output = []\n",
    "\n",
    "h0 = torch.zeros(1, 10) # hidden state at time 0\n",
    "\n",
    "h1 = torch.tanh(E[x[0]] @ W1 + b1) + h0 # hidden state at time 1\n",
    "o1 = h1 @ W2 + b2 # output at time 1\n",
    "output.append(o1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-uAHmSFpFxot"
   },
   "outputs": [],
   "source": [
    "h2 = torch.tanh(E[x[1]] @ W1 + b1) + h1 # hidden state at time 2\n",
    "o2 = h2 @ W2 + b2 # output at time 2\n",
    "output.append(o2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Is-Sj-dGShO"
   },
   "outputs": [],
   "source": [
    "h3 = torch.tanh(E[x[2]] @ W1 + b1) + h2 # hidden state at time 3\n",
    "o3 = h3 @ W2 + b2 # output at time 3\n",
    "output.append(o3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BeHOx2YXEiKr",
    "outputId": "f676a500-b466-49bb-afe8-547e3d6be772"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([ 0.4669,  0.6761, -3.0534,  4.0401, -2.0252, -0.6030, -4.7145, -1.1758,\n",
       "         -2.9580, -1.3555, -0.4534,  0.7445,  0.2072,  1.1551,  2.4621,  2.8646,\n",
       "          0.8427, -3.0760, -6.9223, -3.2064]),\n",
       " tensor([ -0.0721,   1.9245,  -4.9851,   1.5987,  -4.8473,  -1.1260, -12.2899,\n",
       "           1.3603,  -2.3253,  -2.3572,  -2.7218,   0.1825,  -1.3522,   0.3771,\n",
       "           5.8657,   3.4324,   0.3699,  -2.5818, -10.0213,  -3.8439]),\n",
       " tensor([  0.7521,   0.1791,  -4.7636,   1.3742,  -8.6670,   0.2180, -13.1483,\n",
       "           2.4508,  -3.7205,  -0.3108,  -2.5391,  -0.2514,  -1.1757,  -0.9017,\n",
       "           3.9833,   9.8831,  -2.7657,  -3.9826, -17.2085,  -8.0013])]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "goa6zp_HAbRn",
    "outputId": "b138a278-c026-412e-8744-5efc613e6662"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0868, -0.0398, -1.0034,  0.8291],\n",
       "        [ 1.0975,  0.5847, -0.6764,  0.4758],\n",
       "        [-0.3673, -0.9957,  0.8612,  0.9166]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1d7EAP6xAbPa"
   },
   "outputs": [],
   "source": [
    " -> One hot encoding\n",
    "10: olma -> Embedding vector\n",
    "\n",
    "Bu olma -> Context vector\n",
    "Buni olma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iKxlDFF5--pJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qK06bAGu9LaI"
   },
   "outputs": [],
   "source": [
    "train_size = int(.8 * X.shape[0])\n",
    "Xtr, Xts = X[:train_size], X[train_size:]\n",
    "Ytr, Yts = Y[:train_size], Y[train_size:]\n",
    "\n",
    "Dtr = TensorDataset(Xtr, Ytr)\n",
    "Dts = TensorDataset(Xts, Yts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Tc71PCFwcCi"
   },
   "outputs": [],
   "source": [
    "DLtr = DataLoader(Dtr, batch_size=32, shuffle=True, drop_last=True)\n",
    "DLts = DataLoader(Dts, batch_size=32, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nxoc6HUmwdoL"
   },
   "outputs": [],
   "source": [
    "class MLP1(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(config['vocab_size'], config['n_embd'])\n",
    "        self.fc = nn.Linear(config['n_embd'], config['vocab_size'])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b-AYncWe1i47"
   },
   "outputs": [],
   "source": [
    "class MLP2(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.emb = nn.Embedding(config['vocab_size'], config['n_embd'])\n",
    "        self.flat = nn.Flatten(start_dim=3)\n",
    "        self.fc = nn.Linear(config['context_size'] * config['n_embd'], config['vocab_size'])\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.out = nn.Linear(config['vocab_size'], config['vocab_size'])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.emb(x)\n",
    "        x = self.flat(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.tanh(x)\n",
    "        x = self.out(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k6EKgD-Bw8M7"
   },
   "outputs": [],
   "source": [
    "block_size = 8\n",
    "model1 = MLP1({\"vocab_size\": vocab_size, \"n_embd\": 16, \"context_size\": block_size})\n",
    "# model2 = MLP2({\"vocab_size\": vocab_size, \"n_embd\": 16, \"context_size\": block_size})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RyMlxrPYxH7K"
   },
   "outputs": [],
   "source": [
    "for x, y in DLtr:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8gp5TAAaxMKY",
    "outputId": "595fcb28-7180-4f56-c8d5-0964fe5cf485"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[26, 24,  0, 15,  4, 24,  7, 22,  8, 10,  8, 23, 19, 17, 19, 20,  2, 18,\n",
      "         11, 14, 18, 22,  7, 20,  9,  3, 25, 16,  3,  4]])\n",
      "torch.Size([1, 30, 27])\n"
     ]
    }
   ],
   "source": [
    "xtest = torch.randint(0, 27, (1, 30))\n",
    "logits = model1(xtest)\n",
    "print(xtest)\n",
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pIO5BRyT6qsR",
    "outputId": "3ede9eba-b5cd-4887-bb4e-759e81f57845"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5557, -0.2012,  0.0194,  0.6211,  0.5542,  0.0107,  0.5560, -0.8848,\n",
       "         0.1130, -0.1375, -0.4019,  0.3113,  0.1812,  0.0145, -0.3206,  0.2724,\n",
       "         0.4117,  0.2851, -0.3671,  0.4658, -0.1074, -0.2541, -0.1560, -0.1230,\n",
       "        -0.5247,  0.1549, -0.4388], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fc.weight @ model1.emb.weight[24] + model1.fc.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MnJFNvrY3eT-",
    "outputId": "bf1da342-3f78-46c8-fe39-8c638780ac32"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.5557, -0.2012,  0.0194,  0.6211,  0.5542,  0.0107,  0.5560, -0.8848,\n",
       "         0.1130, -0.1375, -0.4019,  0.3113,  0.1812,  0.0145, -0.3206,  0.2724,\n",
       "         0.4117,  0.2851, -0.3671,  0.4658, -0.1074, -0.2541, -0.1560, -0.1230,\n",
       "        -0.5247,  0.1549, -0.4388], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4MvOImMA6cSx",
    "outputId": "4d5e5420-4d2c-4a6b-b958-9f7818d5041f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5557, -0.2012,  0.0194,  0.6211,  0.5542,  0.0107,  0.5560,\n",
       "          -0.8848,  0.1130, -0.1375, -0.4019,  0.3113,  0.1812,  0.0145,\n",
       "          -0.3206,  0.2724,  0.4117,  0.2851, -0.3671,  0.4658, -0.1074,\n",
       "          -0.2541, -0.1560, -0.1230, -0.5247,  0.1549, -0.4388]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1(torch.tensor([[24]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dZKu7QQ454fd"
   },
   "outputs": [],
   "source": [
    "emma.\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fprY5E-U7bDK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CA2ksNZ57a4v"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HCMtYZyf7a2K"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rUX6zjlj54dZ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ad5-ry5kxnkW",
    "outputId": "328e22bf-dc58-4561-ae26-de17fceb3f63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] -> [5]\n",
      "[0, 5] -> [13]\n",
      "[0, 5, 13] -> [13]\n",
      "[0, 5, 13, 13] -> [1]\n",
      "[0, 5, 13, 13, 1] -> [0]\n",
      "[0] -> [15]\n",
      "[0, 15] -> [12]\n",
      "[0, 15, 12] -> [9]\n",
      "[0, 15, 12, 9] -> [22]\n",
      "[0, 15, 12, 9, 22] -> [9]\n",
      "[0, 15, 12, 9, 22, 9] -> [1]\n",
      "[0, 15, 12, 9, 22, 9, 1] -> [0]\n",
      "[0] -> [1]\n",
      "[0, 1] -> [22]\n",
      "[0, 1, 22] -> [1]\n",
      "[0, 1, 22, 1] -> [0]\n",
      "[0] -> [9]\n",
      "[0, 9] -> [19]\n",
      "[0, 9, 19] -> [1]\n",
      "[0, 9, 19, 1] -> [2]\n",
      "[0, 9, 19, 1, 2] -> [5]\n",
      "[0, 9, 19, 1, 2, 5] -> [12]\n",
      "[0, 9, 19, 1, 2, 5, 12] -> [12]\n",
      "[0, 9, 19, 1, 2, 5, 12, 12] -> [1]\n",
      "[0, 9, 19, 1, 2, 5, 12, 12, 1] -> [0]\n"
     ]
    }
   ],
   "source": [
    "block_size = 3\n",
    "for name in names[:4]:\n",
    "    context = [0]\n",
    "    for ch in name + '.':\n",
    "        ix = stoi[ch]\n",
    "        print(f\"{context} -> {[ix]}\")\n",
    "        context = context + [ix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CFWuI5fuyFsX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
