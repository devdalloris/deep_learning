{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Sentence Classification Examples:\n",
        "\n",
        "    1. Sentiment Analysis\n",
        "        1.1 Positive\n",
        "        1.2 Negative\n",
        "        I really hate this music -> Negative -> 0\n",
        "        I love this food -> Positive -> 1\n",
        "    2. Jumla qaysi tilda yozilganini aniqlash\n",
        "    3. Names dataset classification\n",
        "    \n"
      ],
      "metadata": {
        "id": "Li6JRxAVeVzc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install unidecode"
      ],
      "metadata": {
        "id": "DGQlzdKfz_pe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dlL4MMtli3Sn",
        "outputId": "d8625d94-72b8-4a11-cf2e-bd06d17f9e57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from unidecode import unidecode"
      ],
      "metadata": {
        "id": "cqzfu_Ba0JB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /drive/MyDrive/data/names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48Mli7MBi9AT",
        "outputId": "a154f095-33d4-4757-e8ae-1d37b46ca1f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Arabic.txt   English.txt  Irish.txt\tPolish.txt\tSpanish.txt\n",
            "Chinese.txt  French.txt   Italian.txt\tPortuguese.txt\tVietnamese.txt\n",
            "Czech.txt    German.txt   Japanese.txt\tRussian.txt\n",
            "Dutch.txt    Greek.txt\t  Korean.txt\tScottish.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from glob import glob"
      ],
      "metadata": {
        "id": "JqluNlnxn4ql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir = \"/drive/MyDrive/data/names\"\n",
        "file_names = glob(\"*.txt\", root_dir=root_dir)\n",
        "unique_labels = sorted([os.path.splitext(file_name)[0] for file_name in file_names])\n",
        "n_labels = len(unique_labels)\n",
        "\n",
        "idx2label = {idx:label for idx, label in enumerate(unique_labels)}\n",
        "label2idx = {label:idx for idx, label in idx2label.items()}"
      ],
      "metadata": {
        "id": "EjhXjgoFoL4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def replace(name, chars, target):\n",
        "    for char in chars:\n",
        "        name = name.replace(char, target)\n",
        "    return name"
      ],
      "metadata": {
        "id": "AoyeghO61VSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_names = []\n",
        "Y_labels = []\n",
        "\n",
        "for file_name in file_names:\n",
        "    with open(os.path.join(root_dir, file_name), \"rt\", encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            name = line.strip().lower()\n",
        "            name = unidecode(name)\n",
        "\n",
        "            if name == 'to the first page':\n",
        "                continue\n",
        "\n",
        "            name = replace(name, [\",\", '1', \"/b\", \":\", \"\\xa0\"], '')\n",
        "            name = replace(name, ['-'], ' ')\n",
        "\n",
        "            X_names.append(name)\n",
        "            Y_labels.append(os.path.splitext(file_name)[0])"
      ],
      "metadata": {
        "id": "0oW4bfp0pjb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Remove \"To The First Page\" names from dataset\n",
        "2. Replace \",\", '1', \"/B\", \":\", \\xa0 with empty string\n",
        "3. Replace '-' with ' '\n",
        "4. Convert all the following from unicode to ascii:\n",
        "[ 'ß',\n",
        " 'à',\n",
        " 'á',\n",
        " 'ã',\n",
        " 'ä',\n",
        " 'ç',\n",
        " 'è',\n",
        " 'é',\n",
        " 'ê',\n",
        " 'ì',\n",
        " 'í',\n",
        " 'ñ',\n",
        " 'ò',\n",
        " 'ó',\n",
        " 'õ',\n",
        " 'ö',\n",
        " 'ù',\n",
        " 'ú',\n",
        " 'ü',\n",
        " 'ą',\n",
        " 'ł',\n",
        " 'ń',\n",
        " 'ś',\n",
        " 'ż']"
      ],
      "metadata": {
        "id": "KUcZFwYWxw4H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pad_token = '.'\n",
        "pad_token_id = 0\n",
        "\n",
        "unique_chars = [pad_token] + sorted(set(''.join(X_names)))\n",
        "idx2char = {idx:char for idx, char in enumerate(unique_chars)}\n",
        "char2idx = {char:idx for idx, char in idx2char.items()}\n",
        "\n",
        "def encode(name: str) -> list[int]:\n",
        "    return [char2idx[char] for char in name]\n",
        "\n",
        "def decode(ids: list[int]) -> str:\n",
        "    return ''.join(idx2char[i] for i in ids)"
      ],
      "metadata": {
        "id": "6faJqyvqqvKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y = [label2idx[label] for label in Y_labels]\n",
        "X = [encode(name) for name in X_names]"
      ],
      "metadata": {
        "id": "aBbwDsHtwwl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x, x_name, y, y_label in zip(X[:5], X_names[:5], Y[:5], Y_labels[:5]):\n",
        "    print(f\"{str(x):<35} -> {x_name:<10} {y} -> {y_label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvz60OdJ3pqP",
        "outputId": "61dea392-0bcd-4d87-c885-5eebbeb11c19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3, 3, 14, 21, 4, 23, 20, 9]        -> aalsburg   3 -> Dutch\n",
            "[3, 3, 14, 21, 22]                  -> aalst      3 -> Dutch\n",
            "[3, 3, 20, 14, 7]                   -> aarle      3 -> Dutch\n",
            "[3, 5, 10, 22, 7, 20, 7, 16]        -> achteren   3 -> Dutch\n",
            "[3, 5, 10, 22, 10, 17, 24, 7, 16]   -> achthoven  3 -> Dutch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Split data into train and test\n",
        "2. NamesDataset for both train and test\n",
        "3. Data Loader for both train and test with custom `collate` function"
      ],
      "metadata": {
        "id": "eAR_YbjH3vuF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import  train_test_split"
      ],
      "metadata": {
        "id": "c2qtzlAJ3r7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xtr, Xts, Ytr, Yts = train_test_split(X, Y, test_size=0.2, stratify=Y)"
      ],
      "metadata": {
        "id": "ugRQzmZTOXtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class NamesDataset(Dataset):\n",
        "    def __init__(self, X, Y):\n",
        "        self.X = X\n",
        "        self.Y = Y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.Y[idx]\n",
        "\n",
        "Dtr = NamesDataset(Xtr, Ytr)\n",
        "Dts = NamesDataset(Xts, Yts)"
      ],
      "metadata": {
        "id": "otFH0vclOfz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "global_max_n = 20\n",
        "\n",
        "def collate_fn(batch):\n",
        "    # print(batch)\n",
        "    x, y = zip(*batch)\n",
        "    max_n = max(len(row) for row in x)\n",
        "    max_n = global_max_n if max_n > global_max_n else max_n\n",
        "    x_padded = torch.zeros(len(x), max_n, dtype=torch.long)\n",
        "\n",
        "    for i in range(len(x)):\n",
        "        x_padded[i, :len(x[i])] = torch.tensor(x[i][:max_n])\n",
        "\n",
        "    return x_padded, torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "\n",
        "Dltr = DataLoader(Dtr, batch_size=4, shuffle=True, drop_last=True, collate_fn=collate_fn)\n",
        "Dlts = DataLoader(Dts, batch_size=4, shuffle=False, drop_last=False, collate_fn=collate_fn)"
      ],
      "metadata": {
        "id": "zBtbMO4vPLVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx2label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sUhDf49bfbB",
        "outputId": "2d2f74ba-3d79-4327-905e-8f0cd8864aab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'Arabic',\n",
              " 1: 'Chinese',\n",
              " 2: 'Czech',\n",
              " 3: 'Dutch',\n",
              " 4: 'English',\n",
              " 5: 'French',\n",
              " 6: 'German',\n",
              " 7: 'Greek',\n",
              " 8: 'Irish',\n",
              " 9: 'Italian',\n",
              " 10: 'Japanese',\n",
              " 11: 'Korean',\n",
              " 12: 'Polish',\n",
              " 13: 'Portuguese',\n",
              " 14: 'Russian',\n",
              " 15: 'Scottish',\n",
              " 16: 'Spanish',\n",
              " 17: 'Vietnamese'}"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from dataclasses import dataclass\n",
        "\n",
        "class  NamesClassifier(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.emb = nn.Embedding(self.config.vocab_size, self.config.n_embd) # B, T, C\n",
        "        self.conv = nn.Conv1d(self.config.n_embd, self.config.n_conv_channels, self.config.kernel_size)\n",
        "\n",
        "        self.max_pool = nn.AdaptiveMaxPool1d(1)\n",
        "        self.drop = nn.Dropout(self.config.drop_rate)\n",
        "        self.fc = nn.Linear(self.config.n_conv_channels, self.config.n_labels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.emb(x)\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.conv(x)\n",
        "        x = self.max_pool(x)\n",
        "        x = self.drop(x.squeeze())\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    vocab_size: int\n",
        "    n_embd: int\n",
        "    n_conv_channels: int\n",
        "    kernel_size: int\n",
        "    drop_rate: float\n",
        "    n_labels: int\n",
        "\n",
        "config = Config(vocab_size=29, n_embd=16, n_conv_channels=32, kernel_size=3, drop_rate=0.5, n_labels=18)\n",
        "model = NamesClassifier(config)"
      ],
      "metadata": {
        "id": "JEGv0CFDV1FO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjoLFTFxcfHO",
        "outputId": "b0a8b0ca-7722-4c9b-fbf7-083a17a115bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NamesClassifier(\n",
              "  (emb): Embedding(29, 16)\n",
              "  (conv): Conv1d(16, 32, kernel_size=(3,), stride=(1,))\n",
              "  (max_pool): AdaptiveMaxPool1d(output_size=1)\n",
              "  (drop): Dropout(p=0.5, inplace=False)\n",
              "  (fc): Linear(in_features=32, out_features=18, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "n_epochs = 3\n",
        "\n",
        "for epoch in range(1, n_epochs+1):\n",
        "    for x, y in Dltr:\n",
        "        # take x and feed it to the model (not defined yet)\n",
        "        logits = model(x)\n",
        "        loss = F.cross_entropy(logits, y)\n",
        "    # evaluate\n",
        "    break\n",
        "    # save the best model\n"
      ],
      "metadata": {
        "id": "ibifCPKBRtSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy, confusion matrix"
      ],
      "metadata": {
        "id": "cVWUl-nyco6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits = model(x)"
      ],
      "metadata": {
        "id": "afkJYn-7dalL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xn0RXPbcdbs9",
        "outputId": "3d8cbee7-aede-4ac2-ae48-d27f4de76403"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.2658,  0.1072, -0.8136,  0.4002,  0.0481, -0.1837, -1.2992,  0.0684,\n",
              "        -0.4996,  0.5389, -0.3511, -0.7628,  0.1983, -0.4705,  0.5058, -0.0566,\n",
              "         0.7549, -0.1128], grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F.softmax(logits[0], dim=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQWTpwAHdciC",
        "outputId": "95e1c34d-fe9e-4336-ae40-008ee62da7b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0704, 0.0600, 0.0239, 0.0805, 0.0566, 0.0449, 0.0147, 0.0578, 0.0327,\n",
              "        0.0925, 0.0380, 0.0252, 0.0658, 0.0337, 0.0895, 0.0510, 0.1148, 0.0482],\n",
              "       grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F.softmax(logits[0], dim=0).argmax()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxWz5p4Jdh7R",
        "outputId": "2803845f-34b7-4737-c01b-5a6528f7bc9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(16)"
            ]
          },
          "metadata": {},
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "F.softmax(logits[0], dim=0).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7y5uTlIBdoX2",
        "outputId": "d1944466-b79b-4b6e-be70-b8afa65ead4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([18])"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logits[0].argmax()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EiQowoxdrrO",
        "outputId": "2e64140e-5fba-4411-8081-f1fd56d5c9a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(16)"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    }
  ]
}