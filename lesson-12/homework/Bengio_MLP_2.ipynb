{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-bL1jodaPLR"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!wget https://raw.githubusercontent.com/karpathy/makemore/refs/heads/master/names.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIE08iaPEHPf",
        "outputId": "602ce017-ddac-4e90-8588-424f616b08d1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRG6WvnFK-zL"
      },
      "outputs": [],
      "source": [
        "names = open('names.txt').read().splitlines()\n",
        "\n",
        "# tokenizer\n",
        "vocab = sorted(set(''.join(names) + '.'))\n",
        "vocab_size = len(vocab)\n",
        "stoi = {v:k for k, v in enumerate(vocab)}\n",
        "itos = {v:k for k, v in stoi.items()}\n",
        "\n",
        "def decode(seq: list[int]) -> str:\n",
        "    return ''.join([itos[i] for i in seq])\n",
        "\n",
        "def encode(name: str) -> list[int]:\n",
        "    return [stoi[s] for s in name]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIT82hDuKOL9"
      },
      "outputs": [],
      "source": [
        "block_size = 3\n",
        "\n",
        "X = []\n",
        "Y = []\n",
        "\n",
        "for name in names:\n",
        "    context = [0] * block_size\n",
        "    for ch in name + '.':\n",
        "        ix = stoi[ch]\n",
        "        X.append(context)\n",
        "        Y.append(ix)\n",
        "        # print(f\"{context} -> {ix}\")\n",
        "        context = context[1:] + [ix]\n",
        "\n",
        "X = torch.tensor(X)\n",
        "Y = torch.tensor(Y)\n",
        "\n",
        "train_size = int(.8 * X.shape[0])\n",
        "Xtr, Xts = X[:train_size], X[train_size:]\n",
        "Ytr, Yts = Y[:train_size], Y[train_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pDoVYdrMouif"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
        "\n",
        "# class NamesDataset(Dataset):\n",
        "#     def __init__(self, X, Y):\n",
        "#         self.X = X\n",
        "#         self.Y = Y\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         return self.X[idx], self.Y[idx]\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return self.X.shape[0]\n",
        "\n",
        "Dtr = TensorDataset(Xtr, Ytr)\n",
        "Dts = TensorDataset(Xts, Yts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSPf8tkMpbsv"
      },
      "outputs": [],
      "source": [
        "DLtr = DataLoader(Dtr, batch_size=32, shuffle=True, drop_last=True)\n",
        "DLts = DataLoader(Dts, batch_size=32, shuffle=False, drop_last=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQPTW-OH5mgd"
      },
      "outputs": [],
      "source": [
        "class NameGenerator(nn.Module):\n",
        "    def __init__(self, vocab_size, n_embd, block_size, n_hidden):\n",
        "        super().__init__()\n",
        "        self.E = nn.Embedding(vocab_size, n_embd)\n",
        "        self.lin1 = nn.Linear(block_size * n_embd, n_hidden)\n",
        "        self.tanh = nn.Tanh()\n",
        "        self.out = nn.Linear(n_hidden, vocab_size)\n",
        "\n",
        "        torch.nn.init.xavier_uniform_(self.lin1.weight)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, T)\n",
        "        xemb = self.E(x) # x shape: (B, T, C) or (batch_size, block_size, n_embd)\n",
        "        # print(f\"xemb shape: {xemb.shape}\")\n",
        "        B, T, C = xemb.shape\n",
        "        xflat = xemb.view(B, T * C) # (B, T * C) or (batch_size, block_size * n_embd)\n",
        "        # print(f\"xflat shape: {xflat.shape}\")\n",
        "        hpreact = self.lin1(xflat)\n",
        "        h = self.tanh(hpreact)\n",
        "        logits = self.out(h)\n",
        "        return logits\n",
        "\n",
        "n_embd = 2\n",
        "model = NameGenerator(vocab_size, n_embd, block_size=3, n_hidden=50).to(device)\n",
        "model2 = NameGenerator(vocab_size, n_embd=32, block_size=3, n_hidden=150).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "optimizer2 = torch.optim.Adam(model2.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQWyPmqf9frp"
      },
      "outputs": [],
      "source": [
        "def plot_embedding():\n",
        "\n",
        "    w = model.E.weight.cpu().detach().numpy()\n",
        "\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.scatter(w[:, 0], w[:, 1], s=200)\n",
        "\n",
        "    for i in range(27):\n",
        "        char = itos[i]\n",
        "        plt.text(w[i][0], w[i][1], char, ha='center', va='center', color='white')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0C57MBYLPr7"
      },
      "outputs": [],
      "source": [
        "# model hyperparameters\n",
        "n_embd = 2\n",
        "n_hidden = 50\n",
        "\n",
        "E = torch.randn(vocab_size, n_embd)\n",
        "W1 = torch.randn(block_size * n_embd, n_hidden) / ((block_size * n_embd) ** 0.5)\n",
        "b1 = torch.randn(n_hidden) / ((block_size * n_embd) ** 0.5)\n",
        "W2 = torch.randn(n_hidden, vocab_size) * 0.01\n",
        "b2 = torch.randn(vocab_size) * 0\n",
        "\n",
        "params = [E, W1, b1, W2, b2]\n",
        "\n",
        "for param in params:\n",
        "    param.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJsC9wjA9Zk6"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tlma_AdRATnP"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def evaluate(model):\n",
        "    model.eval()\n",
        "\n",
        "    epoch_loss = 0.0\n",
        "    for x, y in DLts:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        logits = model(x)\n",
        "        loss = F.cross_entropy(logits, y)\n",
        "        epoch_loss += loss.item()\n",
        "    epoch_loss /= len(DLts)\n",
        "\n",
        "    return epoch_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XKNpJE0mntxV"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, n_epoch = 10):\n",
        "    torch.manual_seed(42)\n",
        "    lossi = []\n",
        "\n",
        "    for epoch in range(n_epoch):\n",
        "        model.train()\n",
        "        epoch_loss = 0.0\n",
        "        for x, y in DLtr:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            logits = model(x)\n",
        "            loss = F.cross_entropy(logits, y)\n",
        "\n",
        "            # for param in model.parameters():\n",
        "            #     param.grad = None\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            # for param in model.parameters():\n",
        "            #     param.data -= 0.01 * param.grad\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            lossi.append(loss.item())\n",
        "        epoch_loss /= len(DLtr)\n",
        "        eval_loss = evaluate(model)\n",
        "        print(f\"Epoch {epoch+1} | Train Loss: {epoch_loss:.3f} | Eval Loss: {eval_loss:.3f}\")\n",
        "\n",
        "    return lossi\n",
        "        # plot_embedding()\n",
        "        # clear_output(wait=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAPHZjIxCFm7",
        "outputId": "ca679667-ff42-4fbe-b61d-12dd7e419321"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Train Loss: 2.386 | Eval Loss: 2.562\n",
            "Epoch 2 | Train Loss: 2.348 | Eval Loss: 2.538\n",
            "Epoch 3 | Train Loss: 2.322 | Eval Loss: 2.525\n",
            "Epoch 4 | Train Loss: 2.302 | Eval Loss: 2.507\n",
            "Epoch 5 | Train Loss: 2.287 | Eval Loss: 2.505\n",
            "Epoch 6 | Train Loss: 2.276 | Eval Loss: 2.511\n",
            "Epoch 7 | Train Loss: 2.267 | Eval Loss: 2.498\n",
            "Epoch 8 | Train Loss: 2.260 | Eval Loss: 2.490\n",
            "Epoch 9 | Train Loss: 2.255 | Eval Loss: 2.497\n",
            "Epoch 10 | Train Loss: 2.250 | Eval Loss: 2.491\n"
          ]
        }
      ],
      "source": [
        "lossi = train(model, optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VySdSMaCs2K",
        "outputId": "2c10314f-4d78-4856-e413-a191da8cbe18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 | Train Loss: 2.242 | Eval Loss: 2.423\n"
          ]
        }
      ],
      "source": [
        "lossi = train(model2, optimizer2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9jTnSxq9WPd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
